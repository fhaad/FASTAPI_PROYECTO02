{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROYECTO 01 - OPTIMIZACION DE CODIGO\n",
    "\n",
    "1. Se realizara el proyecto 01 una vez mas con el fin de optimizar los procedimientos y el codigo\n",
    "2. Se creara una nueva fastapi(Framework) con conexion a base de datos, nuevas consultas y mejor optimizadas\n",
    "3. Se creara un nuevo contenedor de docker e imagen\n",
    "4. Se realizara el deploy de nuevo con Mogenius\n",
    "5. Se documentara cada codigo con lineas de comentario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importacion de las librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlalchemy as sql\n",
    "from sqlalchemy import create_engine\n",
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de los archivos a DataFrames de Pandas\n",
    "dataset1 = pd.read_csv(r'D:\\Python\\PROYECTO_1_DATA_ENGINEER\\DATASET_RAW\\amazon_prime_titles.csv', sep = ',', encoding = 'utf_8')\n",
    "dataset2 = pd.read_csv(r'D:\\Python\\PROYECTO_1_DATA_ENGINEER\\DATASET_RAW\\disney_plus_titles.csv', sep = ',', encoding = 'utf_8')\n",
    "dataset3 = pd.read_csv(r'D:\\Python\\PROYECTO_1_DATA_ENGINEER\\DATASET_RAW\\hulu_titles.csv', sep = ',', encoding = 'utf_8')\n",
    "dataset4 = pd.read_json(r'D:\\Python\\PROYECTO_1_DATA_ENGINEER\\DATASET_RAW\\netflix_titles.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generacion de reportes tipo EDA con Pandas-Profiling\n",
    "dataset1_amazon_EDA = ProfileReport(dataset1, title=\"Pandas Profiling Report\")\n",
    "dataset2_disney_EDA = ProfileReport(dataset2, title=\"Pandas Profiling Report\")\n",
    "dataset3_hulu_EDA = ProfileReport(dataset3, title=\"Pandas Profiling Report\")\n",
    "dataset4_netflix_EDA = ProfileReport(dataset4, title=\"Pandas Profiling Report\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos los reportes EDA en un directorio\n",
    "dataset1_amazon_EDA.to_file(\"D:\\FASTAPI-PROYECTO01_OPT\\EDA_REPORT\\dataset_amazon.html\")\n",
    "dataset2_disney_EDA.to_file(\"D:\\FASTAPI-PROYECTO01_OPT\\EDA_REPORT\\dataset_disney.html\")\n",
    "dataset3_hulu_EDA.to_file(\"D:\\FASTAPI-PROYECTO01_OPT\\EDA_REPORT\\dataset_hulu.html\")\n",
    "dataset4_netflix_EDA.to_file(\"D:\\FASTAPI-PROYECTO01_OPT\\EDA_REPORT\\dataset_netflix.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1['platform'] = 'amazon'\n",
    "dataset1['new_id'] = 'ama'+ dataset1['show_id']\n",
    "dataset2['platform'] = 'disney'\n",
    "dataset2['new_id'] = 'dis'+ dataset2['show_id']\n",
    "dataset3['platform'] = 'hulu'\n",
    "dataset3['new_id'] = 'hul'+ dataset3['show_id']\n",
    "dataset4['platform'] = 'netflix'\n",
    "dataset4['new_id'] = 'net'+ dataset4['show_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset4.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1['date_added'] = dataset1['date_added'].str.lstrip() # str.lstrip() se usa para eliminar espacios del lado izquierdo de la cadena\n",
    "dataset1['date_added'] = dataset1['date_added'].str.rstrip() # str.rstrip() para eliminar espacios del lado derecho de la cadena\n",
    "# dataset1['date_added'] = dataset1['date_added'].str.lstrip() # str.strip()elimina espacios de ambos lados\n",
    "dataset1['date_added'] = pd.to_datetime(dataset1['date_added'], format='%B %d, %Y') # Cambia el formato\n",
    "\n",
    "dataset2['date_added'] = dataset2['date_added'].str.lstrip() # str.lstrip() se usa para eliminar espacios del lado izquierdo de la cadena\n",
    "dataset2['date_added'] = dataset2['date_added'].str.rstrip() # str.rstrip() para eliminar espacios del lado derecho de la cadena\n",
    "dataset2['date_added'] = pd.to_datetime(dataset2['date_added'], format='%B %d, %Y') # Cambia el formato\n",
    "\n",
    "dataset3['date_added'] = dataset3['date_added'].str.lstrip() # str.lstrip() se usa para eliminar espacios del lado izquierdo de la cadena\n",
    "dataset3['date_added'] = dataset3['date_added'].str.rstrip() # str.rstrip() para eliminar espacios del lado derecho de la cadena\n",
    "dataset3['date_added'] = pd.to_datetime(dataset3['date_added'], format='%B %d, %Y') # Cambia el formato\n",
    "\n",
    "dataset4['date_added'] = dataset4['date_added'].str.lstrip() # str.lstrip() se usa para eliminar espacios del lado izquierdo de la cadena\n",
    "dataset4['date_added'] = dataset4['date_added'].str.rstrip() # str.rstrip() para eliminar espacios del lado derecho de la cadena\n",
    "dataset4['date_added'] = pd.to_datetime(dataset4['date_added'], format='%B %d, %Y') # Cambia el formato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui rellenamos los datos faltantes con un valor predeterminado\n",
    "dataset1['duration'].fillna(0, inplace=True)\n",
    "dataset2['duration'].fillna(0, inplace=True)\n",
    "dataset3['duration'].fillna(0, inplace=True)\n",
    "dataset4['duration'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui rellenamos los datos faltantes con un valor predeterminado\n",
    "dataset1['cast'].fillna(\"sin dato\", inplace=True)\n",
    "dataset2['cast'].fillna(\"sin dato\", inplace=True)\n",
    "dataset3['cast'].fillna(\"sin dato\", inplace=True)\n",
    "dataset4['cast'].fillna(\"sin dato\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En esta linea de codigo dividimos la columna (duration) en 2 tipos, una tipo numerica y otra string\n",
    "dataset1[['min','season']] = dataset1['duration'].str.split(expand=True)\n",
    "dataset2[['min','season']] = dataset1['duration'].str.split(expand=True)\n",
    "dataset3[['min','season']] = dataset1['duration'].str.split(expand=True)\n",
    "dataset4[['min','season']] = dataset1['duration'].str.split(expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La columna (min) de tipo string(str) se convierte a entero(int)\n",
    "dataset1['min'] = dataset1['min'].astype(int)\n",
    "dataset2['min'] = dataset2['min'].astype(int)\n",
    "dataset3['min'] = dataset3['min'].astype(int)\n",
    "dataset4['min'] = dataset4['min'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui rellenamos los datos faltantes con un valor predeterminado\n",
    "dataset1['director'].fillna(\"sin dato\", inplace=True)\n",
    "dataset2['director'].fillna(\"sin dato\", inplace=True)\n",
    "dataset3['director'].fillna(\"sin dato\", inplace=True)\n",
    "dataset4['director'].fillna(\"sin dato\", inplace=True)\n",
    "\n",
    "dataset1['country'].fillna(\"sin dato\", inplace=True)\n",
    "dataset2['country'].fillna(\"sin dato\", inplace=True)\n",
    "dataset3['country'].fillna(\"sin dato\", inplace=True)\n",
    "dataset4['country'].fillna(\"sin dato\", inplace=True)\n",
    "\n",
    "dataset1['rating'].fillna(\"sin dato\", inplace=True)\n",
    "dataset2['rating'].fillna(\"sin dato\", inplace=True)\n",
    "dataset3['rating'].fillna(\"sin dato\", inplace=True)\n",
    "dataset4['rating'].fillna(\"sin dato\", inplace=True)\n",
    "\n",
    "dataset1['description'].fillna(\"sin dato\", inplace=True)\n",
    "dataset2['description'].fillna(\"sin dato\", inplace=True)\n",
    "dataset3['description'].fillna(\"sin dato\", inplace=True)\n",
    "dataset4['description'].fillna(\"sin dato\", inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **ojo** En el proyecto utilizamos la elimnacion de ciertas columnas. En esta optimizacion de codigo no se hizo.\n",
    "\n",
    "# Elimina las filas que no son necesarias y que no afectan los resultados\n",
    "\n",
    "#dataset1_clean = dataset1.drop(['director', 'country', 'date_added', 'rating'], axis=1) \n",
    "#dataset2_clean = dataset2.drop(['director', 'country', 'date_added', 'rating'], axis=1) \n",
    "#dataset3_clean = dataset3.drop(['director', 'country', 'date_added', 'rating'], axis=1) \n",
    "#dataset4_clean = dataset4.drop(['director', 'country', 'date_added', 'rating'], axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En la columna rating se encuentran valores de duration, se crea un filtro para pasar los datos de una columna a otra\n",
    "filtro = (\n",
    "    dataset3[\"rating\"].str.contains(\"min\")\n",
    "    | dataset3[\"rating\"].str.contains(\"Season\")\n",
    "    & dataset3[\"rating\"].notna()\n",
    "    & dataset3[\"duration\"].isna()\n",
    ")\n",
    "dataset3.loc[filtro,\"duration\"] = dataset3.loc[filtro,\"rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedemos a guardar los datos limpios en la carpeta DATA_CLEAN\n",
    "dataset1.to_csv('D:\\FASTAPI-PROYECTO01_OPT\\DATASET_CLEAN\\dataset_amazon_clean.csv', index = False)\n",
    "dataset2.to_csv('D:\\FASTAPI-PROYECTO01_OPT\\DATASET_CLEAN\\dataset_disney_clean.csv', index = False)\n",
    "dataset3.to_csv('D:\\FASTAPI-PROYECTO01_OPT\\DATASET_CLEAN\\dataset_hulu_clean.csv', index = False)\n",
    "dataset4.to_csv('D:\\FASTAPI-PROYECTO01_OPT\\DATASET_CLEAN\\dataset_netflix_clean.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui se hace el procedimiento de concatenar los 4 archivos\n",
    "frames = [dataset1, dataset2, dataset3, dataset4]\n",
    "dataset_new= pd.concat(frames)\n",
    "dataset_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedemos a guardar los datos limpios concatenados concat() en la carpeta DATA_CLEAN\n",
    "dataset_new.to_csv('D:\\FASTAPI-PROYECTO01_OPT\\DATASET_CLEAN\\dataset_new.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22998"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# En esta linea creamos un base de datos sqlite con los datos limpios. Con esta base de datos es qu vamos a realizar las consultas\n",
    "engine = sql.create_engine(\"sqlite:///D:\\FASTAPI-PROYECTO01_OPT/dataset_new.db\")\n",
    "dataset_new.to_sql(name=\"dataset_new\", con=engine, if_exists = \"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui se prueba la conexion a traves de una consulta\n",
    "pd.read_sql('SELECT * FROM dataset_new where platform = \"amazon\" ', engine)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3282607f385ea6f15702157e2a823b97e47a25ad58852c02230532c044fb265d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
